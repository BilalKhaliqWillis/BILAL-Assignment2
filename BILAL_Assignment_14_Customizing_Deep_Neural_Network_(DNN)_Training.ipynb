{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyN9IyK8beBX8j1VGZd2A8rp",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/BilalKhaliqWillis/BILAL-Assignment2/blob/main/BILAL_Assignment_14_Customizing_Deep_Neural_Network_(DNN)_Training.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "4seiPkEXE6Zs"
      },
      "outputs": [],
      "source": [
        "# Assignment 14: Customizing Deep Neural Network (DNN) Training\n",
        "# Importing Required Libraries\n",
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "from tensorflow import keras\n",
        "from tensorflow.keras import layers, regularizers\n",
        "\n",
        "from sklearn.datasets import fetch_california_housing\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import StandardScaler"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Loading the California Housing Dataset\n",
        "# Loading dataset\n",
        "housing = fetch_california_housing()\n",
        "\n",
        "X = housing.data\n",
        "y = housing.target\n",
        "\n",
        "print(\"Feature shape:\", X.shape)\n",
        "print(\"Target shape:\", y.shape)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        },
        "id": "HY4DHXIaFGbL",
        "outputId": "4d278d03-9f3d-4010-82a1-97f3cc34f22f"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Feature shape: (20640, 8)\n",
            "Target shape: (20640,)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Splitting the Dataset (Train / Validation / Test)\n",
        "# First split:- Train + Temp\n",
        "X_train_full, X_test, y_train_full, y_test = train_test_split(\n",
        "    X, y, test_size=0.2, random_state=42\n",
        ")\n",
        "\n",
        "# Second split:- Train / Validation\n",
        "X_train, X_val, y_train, y_val = train_test_split(\n",
        "    X_train_full, y_train_full, test_size=0.2, random_state=42\n",
        ")\n",
        "\n",
        "print(\"Training set:\", X_train.shape)\n",
        "print(\"Validation set:\", X_val.shape)\n",
        "print(\"Test set:\", X_test.shape)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        },
        "id": "St552agIFIIS",
        "outputId": "4f5b9a8b-f6dd-47e9-d57a-48d182d284de"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Training set: (13209, 8)\n",
            "Validation set: (3303, 8)\n",
            "Test set: (4128, 8)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Standardizing the Features\n",
        "scaler = StandardScaler()\n",
        "\n",
        "X_train_scaled = scaler.fit_transform(X_train)\n",
        "X_val_scaled = scaler.transform(X_val)\n",
        "X_test_scaled = scaler.transform(X_test)"
      ],
      "metadata": {
        "id": "IeUiMGazFLOW"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Building the Sequential Model with L2 Regularization\n",
        "model = keras.Sequential([\n",
        "    layers.Dense(\n",
        "        30,\n",
        "        activation=\"relu\",\n",
        "        kernel_regularizer=regularizers.l2(0.05),\n",
        "        input_shape=X_train_scaled.shape[1:]\n",
        "    ),\n",
        "    layers.Dense(1)\n",
        "])\n",
        "\n",
        "model.summary()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 254
        },
        "id": "P_ESYj8LFNSI",
        "outputId": "85b8d75f-d3b5-4559-d853-44bb2cb0efb8"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/keras/src/layers/core/dense.py:93: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
            "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1mModel: \"sequential\"\u001b[0m\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"sequential\"</span>\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
              "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                   \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape          \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
              "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
              "│ dense (\u001b[38;5;33mDense\u001b[0m)                   │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m30\u001b[0m)             │           \u001b[38;5;34m270\u001b[0m │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ dense_1 (\u001b[38;5;33mDense\u001b[0m)                 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1\u001b[0m)              │            \u001b[38;5;34m31\u001b[0m │\n",
              "└─────────────────────────────────┴────────────────────────┴───────────────┘\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
              "┃<span style=\"font-weight: bold\"> Layer (type)                    </span>┃<span style=\"font-weight: bold\"> Output Shape           </span>┃<span style=\"font-weight: bold\">       Param # </span>┃\n",
              "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
              "│ dense (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                   │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">30</span>)             │           <span style=\"color: #00af00; text-decoration-color: #00af00\">270</span> │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ dense_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>)              │            <span style=\"color: #00af00; text-decoration-color: #00af00\">31</span> │\n",
              "└─────────────────────────────────┴────────────────────────┴───────────────┘\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m301\u001b[0m (1.18 KB)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">301</span> (1.18 KB)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m301\u001b[0m (1.18 KB)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">301</span> (1.18 KB)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Defining the Loss Function, Optimizer and Metrics\n",
        "loss_fn = keras.losses.MeanSquaredError()\n",
        "\n",
        "optimizer = keras.optimizers.SGD(learning_rate=0.01)\n",
        "\n",
        "train_mae = keras.metrics.MeanAbsoluteError()\n",
        "val_mae = keras.metrics.MeanAbsoluteError()"
      ],
      "metadata": {
        "id": "emWI_xZ7FPYs"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Preparing the Dataset Using tf.data\n",
        "batch_size = 32\n",
        "\n",
        "train_dataset = tf.data.Dataset.from_tensor_slices(\n",
        "    (X_train_scaled, y_train)\n",
        ").shuffle(1000).batch(batch_size)\n",
        "\n",
        "val_dataset = tf.data.Dataset.from_tensor_slices(\n",
        "    (X_val_scaled, y_val)\n",
        ").batch(batch_size)"
      ],
      "metadata": {
        "id": "dEytG5ZNFR1J"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Custom Training Loop Using GradientTape\n",
        "epochs = 10\n",
        "\n",
        "for epoch in range(epochs):\n",
        "    print(f\"\\nEpoch {epoch + 1}/{epochs}\")\n",
        "\n",
        "    # Reset metrics\n",
        "    train_mae.reset_state()\n",
        "    val_mae.reset_state()\n",
        "\n",
        "    # Training loop\n",
        "    for X_batch, y_batch in train_dataset:\n",
        "        with tf.GradientTape() as tape:\n",
        "            predictions = model(X_batch, training=True)\n",
        "            loss = loss_fn(y_batch, predictions)\n",
        "            loss += sum(model.losses)  # L2 regularization loss\n",
        "\n",
        "        gradients = tape.gradient(loss, model.trainable_variables)\n",
        "        optimizer.apply_gradients(zip(gradients, model.trainable_variables))\n",
        "\n",
        "        train_mae.update_state(y_batch, predictions)\n",
        "\n",
        "    # Validation loop\n",
        "    for X_batch, y_batch in val_dataset:\n",
        "        val_predictions = model(X_batch, training=False)\n",
        "        val_mae.update_state(y_batch, val_predictions)\n",
        "\n",
        "    print(f\"Train MAE: {train_mae.result():.4f}\")\n",
        "    print(f\"Validation MAE: {val_mae.result():.4f}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        },
        "id": "eugXJTEHFT8-",
        "outputId": "c8777055-0d33-49d9-8454-3e32f2960029"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Epoch 1/10\n",
            "Train MAE: 0.5990\n",
            "Validation MAE: 0.4868\n",
            "\n",
            "Epoch 2/10\n",
            "Train MAE: 0.4683\n",
            "Validation MAE: 0.4878\n",
            "\n",
            "Epoch 3/10\n",
            "Train MAE: 0.4645\n",
            "Validation MAE: 0.4831\n",
            "\n",
            "Epoch 4/10\n",
            "Train MAE: 0.4641\n",
            "Validation MAE: 0.4812\n",
            "\n",
            "Epoch 5/10\n",
            "Train MAE: 0.4628\n",
            "Validation MAE: 0.4857\n",
            "\n",
            "Epoch 6/10\n",
            "Train MAE: 0.4628\n",
            "Validation MAE: 0.4906\n",
            "\n",
            "Epoch 7/10\n",
            "Train MAE: 0.4619\n",
            "Validation MAE: 0.4687\n",
            "\n",
            "Epoch 8/10\n",
            "Train MAE: 0.4613\n",
            "Validation MAE: 0.4767\n",
            "\n",
            "Epoch 9/10\n",
            "Train MAE: 0.4608\n",
            "Validation MAE: 0.4757\n",
            "\n",
            "Epoch 10/10\n",
            "Train MAE: 0.4590\n",
            "Validation MAE: 0.4834\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Evaluating on the Test Set\n",
        "test_predictions = model(X_test_scaled, training=False)\n",
        "test_mae = keras.metrics.MeanAbsoluteError()\n",
        "test_mae.update_state(y_test, test_predictions)\n",
        "\n",
        "print(\"Test MAE:\", test_mae.result().numpy())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        },
        "id": "NCw69cctFWj4",
        "outputId": "e41899a3-1241-4aef-b0f0-e5b9934ed313"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Test MAE: 0.4747899\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Answers:-\n",
        "1. How do custom training loops differ from Keras’ fit() method?\n",
        "- Custom training loops require manual control over forward passes, loss computation, gradient calculation and parameter updates.\n",
        "The fit() method automates these steps making it simpler but less flexible.\n",
        "\n",
        "2. Benefits and Challenges of Custom Training Loops\n",
        "- Benefits:-\n",
        "•\tFull control over training logic\n",
        "•\tEasier implementation of custom losses and metrics\n",
        "•\tGreater flexibility for research and experimentation\n",
        "- Challenges:-\n",
        "•\tMore code to write and debug\n",
        "•\tHigher risk of implementation errors\n",
        "•\tLess beginner-friendly than fit()\n"
      ],
      "metadata": {
        "id": "z3WIRUwuFgbJ"
      }
    }
  ]
}